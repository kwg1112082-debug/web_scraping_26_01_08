import requests
from bs4 import BeautifulSoup

# ==========================================================
# [ì„¤ì •] ìŠ¤í¬ë˜í•‘í•  ëŒ€ìƒ URL ë° ì˜µì…˜
# ==========================================================
TARGET_URL = "https://news.naver.com/section/104"
MAX_NEWS_LIMIT = 50  # ìµœëŒ€ ìˆ˜ì§‘í•  ë‰´ìŠ¤ ê°œìˆ˜

def main():
    # 1ë‹¨ê³„: ì›¹í˜ì´ì§€ ìš”ì²­ (Requests) - [ver.3 ê¸°ëŠ¥: ì•ˆì „ì„± ê°•í™”]
    print(f"\n[ì ‘ì† ì‹œë„] {TARGET_URL} ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤...")
    
    try:
        # timeout=5: 5ì´ˆ ì•ˆì— ì‘ë‹µì´ ì—†ìœ¼ë©´ ì—ëŸ¬ ë°œìƒ (ë¬´í•œ ëŒ€ê¸° ë°©ì§€)
        response = requests.get(TARGET_URL, timeout=5)
        
        # HTTP ìƒíƒœ ì½”ë“œ ê²€ì‚¬
        if response.status_code != 200:
            print(f"âŒ ì ‘ì† ì‹¤íŒ¨! ìƒíƒœ ì½”ë“œ: {response.status_code}")
            return
            
    except Exception as e:
        print(f"âŒ ì ‘ì† ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return

    print("âœ… ì ‘ì† ì„±ê³µ! HTML ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n")


    # 2ë‹¨ê³„: HTML íŒŒì‹± (BeautifulSoup)
    soup = BeautifulSoup(response.text, "lxml")


    # 3ë‹¨ê³„: ë‰´ìŠ¤ ë°ì´í„° ì¶”ì¶œ
    
    # [ver.3 ê¸°ëŠ¥: ì„¹ì…˜ ì œëª© ì¶”ì¶œ]
    section_title_tag = soup.select_one(".sa_head_link")
    if section_title_tag:
        section_name = section_title_tag.get_text(strip=True)
        print(f"ğŸ“Œ í˜„ì¬ ì„¹ì…˜: {section_name}")
    else:
        print("ğŸ“Œ ì„¹ì…˜ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # ë„¤ì´ë²„ ë‰´ìŠ¤ ëª©ë¡ì˜ ê° ê¸°ì‚¬ëŠ” <div class="sa_text"> ì•ˆì— ë‹´ê²¨ ìˆìŠµë‹ˆë‹¤.
    articles = soup.select('.sa_text')
    
    # ìˆ˜ì§‘ ê°œìˆ˜ ì œí•œ (slicing ì‚¬ìš©)
    articles = articles[:MAX_NEWS_LIMIT]
    
    print(f"[{MAX_NEWS_LIMIT}ê°œ ì œí•œ] íƒìƒ‰ëœ ê¸°ì‚¬ ìš”ì†Œ ê°œìˆ˜: {len(articles)}ê°œ")
    print("=" * 60)

    # ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    news_data_list = []

    for article in articles:
        # (1) ì œëª© ë° ë§í¬ ì¶”ì¶œ using CSS Selector
        # <a class="sa_text_title" href="..."> ... </a>
        title_tag = article.select_one('.sa_text_title')
        
        # ì œëª© íƒœê·¸ê°€ ì—†ëŠ” ê²½ìš°(ê´‘ê³  ë“±)ëŠ” ê±´ë„ˆëœ€
        if not title_tag:
            continue
            
        # ì œëª© í…ìŠ¤íŠ¸ (strong íƒœê·¸ ì•ˆ)
        strong_tag = title_tag.select_one('.sa_text_strong')
        title_text = strong_tag.get_text(strip=True) if strong_tag else title_tag.get_text(strip=True)
        
        # ê¸°ì‚¬ ë§í¬ (href ì†ì„±)
        article_link = title_tag['href']

        # (2) ê¸°ì‚¬ ìš”ì•½ ë‚´ìš© ì¶”ì¶œ
        # ëª©ë¡ì—ì„œ ë³´ì´ëŠ” ì§¤ë§‰í•œ ë‚´ìš© (sa_text_lede)
        lede_tag = article.select_one('.sa_text_lede')
        content_text = lede_tag.get_text(strip=True) if lede_tag else "ë‚´ìš© ë¯¸ë¦¬ë³´ê¸° ì—†ìŒ"

        # (3) ì–¸ë¡ ì‚¬ ì •ë³´ ì¶”ì¶œ
        press_tag = article.select_one('.sa_text_press')
        press_name = press_tag.get_text(strip=True) if press_tag else "ì–¸ë¡ ì‚¬ ì •ë³´ ì—†ìŒ"

        # ë”•ì…”ë„ˆë¦¬ë¡œ ë¬¶ì–´ì„œ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
        news_info = {
            "press": press_name,
            "title": title_text,
            "content": content_text,
            "link": article_link
        }
        news_data_list.append(news_info)


    # 4ë‹¨ê³„: ê²°ê³¼ ì¶œë ¥
    for idx, news in enumerate(news_data_list, start=1):
        print(f"ğŸ“° No.{idx}")
        print(f"   ì‹ ë¬¸ì‚¬: {news['press']}")
        print(f"   ì œëª©: {news['title']}")
        print(f"   ë‚´ìš©: {news['content']}...")
        print(f"   ë§í¬: {news['link']}")
        print("-" * 60)

    print(f"\nâœ… ìµœì¢… ìˆ˜ì§‘ ì™„ë£Œ: ì´ {len(news_data_list)}ê°œì˜ ë‰´ìŠ¤ë¥¼ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤.")

# ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
if __name__ == "__main__":
    main()
